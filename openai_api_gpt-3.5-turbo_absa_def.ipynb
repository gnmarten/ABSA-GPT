{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABSA via gpt-3.5-turbo\n",
    "\n",
    "uses the cheaper model, but this is zero-shot and hence less consistent in formatting the output as JSON\n",
    "\n",
    "this file is self-contained and does not require any external files (other than your csv)\n",
    "\n",
    "original inspiration from Twitter, expanded with lots of suggestions by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import subprocess\n",
    "import requests\n",
    "from typing import List, Optional\n",
    "from pprint import pprint\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" \n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#GPT_MODEL = [\"text-davinci-003\"]\n",
    "\n",
    "def print_response(response):\n",
    "    if response.status_code == 200:\n",
    "        print(response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        error = response.json()\n",
    "        print(f\"Error: {error['error']}\")\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Setup OPENAI_API_KEY\n",
    "\n",
    "# Setup logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"%(asctime)s | %(levelname)s | %(message)s\", level=logging.INFO)\n",
    "\n",
    "# Update sys.path (or use PYTHONPATH)\n",
    "\n",
    "#sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from tqdm.notebook import tqdm\n",
    "#from absa.analysis.gpt3 import analyze\n",
    "from json import loads\n",
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "\n",
    "analysis_results = []\n",
    "extra_prompts = []\n",
    "\n",
    "logging.getLogger(\"openai\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create completion\n",
    "- DOC url: https://platform.openai.com/docs/api-reference/completions/create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/completions\", \\\n",
    "    headers=headers, json={\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"prompt\": \"Say this is a test\",\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    ")\n",
    "\n",
    "def create_completion(messages:str, suffix:str = None, model: str = \"gpt-3.5-turbo\", max_tokens: Optional[int] = 500, temperature: float = 1, top_p: Optional[int] = 1, n: Optional[int] = 1,  stream: Optional[bool] = False, echo: Optional[bool] = False):\n",
    "    \"\"\"\n",
    "    https://platform.openai.com/docs/api-reference/completions/create\n",
    "    ##### Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.\n",
    "\n",
    "    Args:\n",
    "        - prompt (str): \n",
    "            - The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays. \n",
    "            Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document. \n",
    "        \n",
    "        - suffix (str): \n",
    "            - The suffix that comes after a completion of inserted text.\n",
    "        \n",
    "        - model (str, required): \n",
    "            - ID of the model to use. You can use the **List models** API to see all of your available models, or see our **Model overview** for descriptions of them. Defaults to \"text-davinci-003\".\n",
    "        \n",
    "        - max_tokens (int, optional, Default: 500): \n",
    "            - The maximum number of tokens to generate in the completion.\n",
    "                The token count of your prompt plus `max_tokens` cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096). Defaults to 500.\n",
    "        \n",
    "        - temperature (float, optional): \n",
    "            - What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "            We generally recommend altering this or `top_p` but not both. Defaults to 0.\n",
    "            \n",
    "        - top_p (float, optional):\n",
    "            - An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n",
    "            - We generally recommend altering this or `temperature` but not both. Defaults to 1.\n",
    "            \n",
    "        - n (int, optional, Default: 1):\n",
    "            - The number of completions to generate. Defaults to 1. \n",
    "        \n",
    "        - stream (bool, optional): \n",
    "            - Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message. Defaults to False.\n",
    "        \n",
    "        - echo (bool, optional): _description_. Defaults to False.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    response = requests.post(\"https://api.openai.com/v1/completions\", \\\n",
    "        headers=headers, json={\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"suffix\": suffix,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"stream\": stream,\n",
    "            \"echo\": echo,\n",
    "            \"stop\": suffix,\n",
    "            \"n\": n,\n",
    "            \"top_p\": top_p\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "    \n",
    "def edit_prompt(instruction: str, input: Optional[str] = None, model: str = \"text-davinci-edit-001\", num: Optional[int] = 1, temperature: Optional[float] = 1, top_p: Optional[float] = 1):\n",
    "    \"\"\"#### Given a prompt and an instruction, the model will return an edited version of the prompt.\n",
    "    https://platform.openai.com/docs/api-reference/edits\n",
    "    Args:\n",
    "        - instruction (str, required): \n",
    "            - The instruction that tells the model how to edit the prompt.\n",
    "            \n",
    "        - input (Optional[str], optional): \n",
    "            - The input text to use as a starting point for the edit. Defaults to None.\n",
    "        \n",
    "        - model (str, required): \n",
    "            - ID of the model to use. You can use the `text-davinci-edit-001` or `code-davinci-edit-001` model with this endpoint. Defaults to \"text-davinci-edit-001\".\n",
    "\n",
    "        - n (Optional[int], optional): \n",
    "            - How many edits to generate for the input and instruction. Defaults to 1.\n",
    "\n",
    "        - temperature (Optional[float], optional): \n",
    "            - What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "            - We generally recommend altering this or `top_p` but not both. Defaults to 1.\n",
    "        \n",
    "        - top_p (Optional[float], optional):\n",
    "            - An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n",
    "            - We generally recommend altering this or `temperature` but not both. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        - response\n",
    "    \"\"\"    \n",
    "    response = requests.post(\"https://api.openai.com/v1/edits\", \\\n",
    "        headers=headers, json={\n",
    "            \"model\": model,\n",
    "            \"input\": input,\n",
    "            \"instruction\": instruction,\n",
    "            \"n\": num,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "labels=pd.read_csv(\"./Ingeborg-Bachmann-Preis_Twitter_2014.csv\",quotechar='\"', escapechar='\\\\', error_bad_lines=False, doublequote=True, sep=\";\", encoding=\"utf-8\")\n",
    "df=labels[~labels.duplicated(subset=\"id\",keep=\"first\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].astype(str)\n",
    "df_duplicates = df[df.duplicated(subset='title', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting for ids that weren't unique\n",
    "import csv\n",
    "import pandas as pd\n",
    "labels=pd.read_csv(\"./2011-2014/jury_output2015def_transformed.csv\",quotechar='\"', doublequote=True, sep=\"|\", encoding=\"utf-8\")\n",
    "#labels['title'] = labels['permalink'].str.split('/').str[-1] #dit was nodig omdat de ids niet uniek waren in scientific notation\n",
    "len(labels)\n",
    "print(labels.head())\n",
    "df=labels\n",
    "#df=labels[~labels.duplicated(subset=\"id\",keep=\"first\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rename(columns = {'Document':'title', 'Title':'text'}, inplace = True)\n",
    "df=labels\n",
    "df.rename(columns = {'result_index':'title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one works, but forgot what is specific about this attempt\n",
    "import time \n",
    "import traceback\n",
    "from textwrap import dedent\n",
    "from random import choice\n",
    "from tqdm.notebook import tqdm\n",
    "#from absa.analysis.gpt3 import analyze\n",
    "from json import loads\n",
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "import time\n",
    "from json import JSONDecodeError, loads\n",
    "from tqdm import tqdm\n",
    "\n",
    "retry_attempts = 3\n",
    "retry_delay = 2\n",
    "analysis_results = []\n",
    "extra_prompts = []\n",
    "\n",
    "completion_text_conversation = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance by extracting \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Gmünder, Kegel, Kastberger, Keller, Feßmann, Steiner needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Dinić, Dorian, Gardi, Lehn, Macht, Özdogan, Otoo, Sargnagel, Schenk, Schneider, Snela, Sozio, Wolf, Zwicky. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a list of JSON objects. The confidence score is represented as a string in the output. The order of the list of JSON objects is the same as the order in which the opinions were expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2007 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance by extracting \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Sulzer, Feßmann, Spinnen, Jandl, Fleischanderl, Winkels, Keller, Mangold, Strigl, Heiz, März, Nüchtern, Ebel, Rakusa, Corino, Radisch needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Janesch, Altwasser, Kloeble, Mezger, Elmiger, Ballhausen, Scharnigg, Scholz, Zander, Kleindienst, Wawerzinek, Schmidt, Fries, Rossbacher, Langenegger, Weiss, Krampitz, Preisendörfer, Neudecker, Stift, Bönt, Ruch, Petersen, Schäfer, Sander, Winkler, Born, Satanik, Palzhoff, Bronsky, Setz, Reitzer, Arndt, Findeis, Orths, Geißler, Mohafez, Hintze, Lenz, Ziegler, Rammstedt, Selg, Marinič, Bernhardt, Schmidt, Grill, Albrecht, Schley, Seiler, Scheuermann, Reng, Zwicky, Stavarič, Oda, Oesterle, PeterLicht, Böttcher, Kern, Stangl, Becker. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a list of JSON objects. The confidence score is represented as a string in the output. The order of the list of JSON objects is the same as the order in which the opinions were expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target in each sentence separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2014 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance. The aspect categories and their aspect terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Dusini, Feßmann, Steiner, Winkels, Strigl, Spinnen, Sulzer, Jandl, Caduff, Keller needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Marchel, Preiwuß, Sommer, Klemm, Flor, Heier, Pölzl, Varatharajah, Fehr, Ganzoni, Gericke, Rubinowitz, Petz, Köhler, Boehning, Meyerhoff, Kegele, Güntner, Mueller, Rock, Simon, Helle, Schönthaler, Petrowskaja, Dübgen, Ehrlich, Maack, Mehlhorn, Moster, Ramnek, Richner, Stichmann, Hassinger, Mahlke, Travnicek, Martynova, Kränzler, Froehling, Nawrat, Senkel, Federmair, Feimer, Geltinger, Steinbeis, Wisser, Praßler, Baum, Reichlin, Haderlap, Rabinowich, Bußmann, Popp, Randt, Richter, Božiković, Klupp. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a JSON object or a list of JSON objects comprising \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" and their values as list of dictionaries as the top-level objects. Do not add \\\"results\\\", \\\"aspect_extraction\\\" or other descriptive terms as top-level JSON object. The confidence score is represented as a string in the output. The order is the same as the order expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2015 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance. The aspect categories and their aspect terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Strigl, Spinnen, Dusini, Feßmann, Steiner, Keller, Jandl needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Marchel, Preiwuß, Sommer, Klemm, Flor, Heier, Pölzl, Varatharajah, Fehr, Ganzoni, Gericke, Rubinowitz, Petz, Köhler, Boehning, Meyerhoff, Kegele, Güntner, Mueller, Rock, Simon, Helle, Schönthaler, Petrowskaja, Dübgen, Ehrlich, Maack, Mehlhorn. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a JSON object or a list of JSON objects comprising as key-value pairs \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" as list of dictionaries as the top-level objects. Do not add \\\"results\\\", \\\"aspect_extraction\\\" or other descriptive terms as top-level JSON object. The confidence score is represented as a string in the output. The order is the same as the order expressed in the text. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. If a single entity mentioned in the text seems to belong to multiple aspect categories and terms, select the most likely aspect category and aspect term out of the list.\\n\\n\n",
    "\"\"\"\n",
    "logging.getLogger(\"openai\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing reviews\"):\n",
    "    try:\n",
    "        if pd.notnull(row[\"title\"]):\n",
    "            title = row[\"title\"]\n",
    "            text = row[\"text\"]\n",
    "            log.info(f\"Analyzing feedback - \\nID: {row['title']}\\nTitle: {title}\\nText: {text}\\n\")\n",
    "\n",
    "            res = create_completion(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=\"0.2\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\",    \"content\": \"You are a data analyst that provides multi-target quadruple sentiment extraction.\"},\n",
    "                    {\"role\": \"system\",    \"content\": \"You annotate multiple opinion targets per line if the text contains more than one target. You annotate every single target only once. Do not invent aspect categories or aspect terms yourself.\"},\n",
    "                    {\"role\": \"user\",      \"content\": completion_text_conversation2015 + text + \":\"},    \n",
    "                    #{\"role\": \"user\",      \"content\": \"What is the most likely \"},\n",
    "                    #{\"role\": \"user\",      \"content\": \"Where are most of the students from?\"},\n",
    "                    #{\"role\": \"user\",      \"content\": \"Which extra-curricular activity/activities is most popular? Which among them has the highest female participation?\"},\n",
    "                    # add in as many questions as you want\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                raw_json = res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                #print(raw_json)\n",
    "                json_data = loads(raw_json)\n",
    "                analysis_results.append(json_data)\n",
    "\n",
    "                log.debug(f\"JSON response: {pprint(json_data)}\")\n",
    "\n",
    "                extra_prompts.append(f\"\\n{text}\\n{raw_json}\")\n",
    "\n",
    "            except JSONDecodeError as e:\n",
    "                if \"Unfortunately, it seems that there is no text provided in your request for me to perform sentiment extraction on.\" in str(e):\n",
    "                    log.error(\"No text provided for sentiment analysis\")\n",
    "                    analysis_results.append(\"No text provided for sentiment analysis\")\n",
    "                elif \"Expecting value\" in str(e):\n",
    "                    if \"Unterminated string\" in str(e):\n",
    "                        log.warning(\"JSON string is unterminated\")\n",
    "                        analysis_results.append(raw_json)\n",
    "                    elif \"I'm sorry, but I need some text to perform the sentiment extraction\" in str(e):\n",
    "                        log.error(\"No text provided for sentiment analysis\")\n",
    "                        analysis_results.append(\"No text provided for sentiment analysis\")\n",
    "                    else:\n",
    "                        log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "                        analysis_results.append([])\n",
    "                else:\n",
    "                    log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "                    analysis_results.append([])\n",
    "            except Exception as e:\n",
    "                log.error(f\"Error performing sentiment analysis on text: {text}\")\n",
    "                log.error(str(e))\n",
    "                analysis_results.append([])\n",
    "        else:\n",
    "            log.warning(f\"No id found in row {i}. Skipping analysis.\")\n",
    "            analysis_results.append([])\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        log.warning(f\"The error ecountered, {i}. Skipping analysis.\")\n",
    "        analysis_results.append([])\n",
    "        \n",
    "    #time.sleep(2) #added 2 seconds delay between requests\n",
    "\n",
    "df[\"analysis\"] = analysis_results\n",
    "df.to_csv(\"./feedbacks_analysis_2015_jury_batch1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filehandling stuff exceptions (my Ids were not unique in scientific notation)\n",
    "import csv\n",
    "import pandas as pd\n",
    "labels=pd.read_csv(\"./2011-2014/jury_output2015def_transformed.csv\",quotechar='\"', doublequote=True, sep=\"|\", encoding=\"utf-8\")\n",
    "labels['title'] = labels['permalink'].str.split('/').str[-1] #dit was nodig omdat de ids niet uniek waren in scientific notation\n",
    "len(labels)\n",
    "print(labels.head())\n",
    "df=labels\n",
    "#df=labels[~labels.duplicated(subset=\"id\",keep=\"first\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=labels[~labels.duplicated(subset=\"title\",keep=\"first\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rename(columns = {'Document':'title', 'Title':'text'}, inplace = True)\n",
    "df=labels\n",
    "df.rename(columns = {'id':'title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df[\"title\"]\n",
    "len(df[ids.isin(ids[ids.duplicated()])].sort_values(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting everything together for testing\n",
    "import time \n",
    "from textwrap import dedent\n",
    "from random import choice\n",
    "from tqdm.notebook import tqdm\n",
    "from absa.analysis.gpt3 import analyze\n",
    "from json import loads\n",
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "import time\n",
    "from json import JSONDecodeError, loads\n",
    "from tqdm import tqdm\n",
    "\n",
    "retry_attempts = 3\n",
    "retry_delay = 2\n",
    "analysis_results = []\n",
    "extra_prompts = []\n",
    "#\n",
    "completion_text_conversation = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance by extracting \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Gmünder, Kegel, Kastberger, Keller, Feßmann, Steiner needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Dinić, Dorian, Gardi, Lehn, Macht, Özdogan, Otoo, Sargnagel, Schenk, Schneider, Snela, Sozio, Wolf, Zwicky. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a list of JSON objects. The confidence score is represented as a string in the output. The order of the list of JSON objects is the same as the order in which the opinions were expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2007 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance by extracting \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Sulzer, Feßmann, Spinnen, Jandl, Fleischanderl, Winkels, Keller, Mangold, Strigl, Heiz, März, Nüchtern, Ebel, Rakusa, Corino, Radisch needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Janesch, Altwasser, Kloeble, Mezger, Elmiger, Ballhausen, Scharnigg, Scholz, Zander, Kleindienst, Wawerzinek, Schmidt, Fries, Rossbacher, Langenegger, Weiss, Krampitz, Preisendörfer, Neudecker, Stift, Bönt, Ruch, Petersen, Schäfer, Sander, Winkler, Born, Satanik, Palzhoff, Bronsky, Setz, Reitzer, Arndt, Findeis, Orths, Geißler, Mohafez, Hintze, Lenz, Ziegler, Rammstedt, Selg, Marinič, Bernhardt, Schmidt, Grill, Albrecht, Schley, Seiler, Scheuermann, Reng, Zwicky, Stavarič, Oda, Oesterle, PeterLicht, Böttcher, Kern, Stangl, Becker. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a list of JSON objects. The confidence score is represented as a string in the output. The order of the list of JSON objects is the same as the order in which the opinions were expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target in each sentence separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2014 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance. The aspect categories and their aspect terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Dusini, Feßmann, Steiner, Winkels, Strigl, Spinnen, Sulzer, Jandl, Caduff, Keller needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Marchel, Preiwuß, Sommer, Klemm, Flor, Heier, Pölzl, Varatharajah, Fehr, Ganzoni, Gericke, Rubinowitz, Petz, Köhler, Boehning, Meyerhoff, Kegele, Güntner, Mueller, Rock, Simon, Helle, Schönthaler, Petrowskaja, Dübgen, Ehrlich, Maack, Mehlhorn, Moster, Ramnek, Richner, Stichmann, Hassinger, Mahlke, Travnicek, Martynova, Kränzler, Froehling, Nawrat, Senkel, Federmair, Feimer, Geltinger, Steinbeis, Wisser, Praßler, Baum, Reichlin, Haderlap, Rabinowich, Bußmann, Popp, Randt, Richter, Božiković, Klupp. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a JSON object or a list of JSON objects comprising as key-value pairs \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" as list of dictionaries as the top-level objects. Do not add \\\"results\\\", \\\"aspect_extraction\\\" or other descriptive terms as top-level JSON object. The confidence score is represented as a string in the output. The order is the same as the order expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2015 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance. The aspect categories and their aspect terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Strigl, Spinnen, Dusini, Feßmann, Steiner, Keller, Jandl needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Marchel, Preiwuß, Sommer, Klemm, Flor, Heier, Pölzl, Varatharajah, Fehr, Ganzoni, Gericke, Rubinowitz, Petz, Köhler, Boehning, Meyerhoff, Kegele, Güntner, Mueller, Rock, Simon, Helle, Schönthaler, Petrowskaja, Dübgen, Ehrlich, Maack, Mehlhorn. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a JSON object or a list of JSON objects comprising as key-value pairs \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" as list of dictionaries as the top-level objects. Do not add \\\"results\\\", \\\"aspect_extraction\\\" or other descriptive terms as top-level JSON object. The confidence score is represented as a string in the output. The order is the same as the order expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "logging.getLogger(\"openai\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df)), desc=\"Analyzing reviews\"):\n",
    "    if pd.notnull(df.loc[i, \"title\"]):\n",
    "        title = df.loc[i, \"title\"]\n",
    "        text = df.loc[i, \"text\"]\n",
    "        log.info(f\"Analyzing feedback - \\nID: {df.loc[i, 'title']}\\nTitle: {title}\\nText: {text}\\n\")\n",
    "\n",
    "        res = create_completion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=\"0.2\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\",    \"content\": \"You are a data analyst that provides multi-target quadruple sentiment extraction.\"},\n",
    "                {\"role\": \"system\",    \"content\": \"You annotate multiple opinion targets per line if the text contains more than one target. You annotate every single target only once. Hashtags and weblinks are not targets. Do not invent aspect categories or aspect terms yourself.\"},\n",
    "                {\"role\": \"user\",      \"content\": completion_text_conversation2015 + text + \":\"},    \n",
    "                #{\"role\": \"user\",      \"content\": \"What is the most likely \"},\n",
    "                #{\"role\": \"user\",      \"content\": \"Where are most of the students from?\"},\n",
    "                #{\"role\": \"user\",      \"content\": \"Which extra-curricular activity/activities is most popular? Which among them has the highest female participation?\"},\n",
    "                # add in as many questions as you want\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            raw_json = res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            #print(raw_json)\n",
    "            json_data = loads(raw_json)\n",
    "            analysis_results.append(json_data)\n",
    "\n",
    "            log.debug(f\"JSON response: {pprint(json_data)}\")\n",
    "\n",
    "            extra_prompts.append(f\"\\n{text}\\n{raw_json}\")\n",
    "\n",
    "        except JSONDecodeError as e:\n",
    "            if \"Unfortunately, it seems that there is no text provided in your request for me to perform sentiment extraction on.\" in str(e):\n",
    "                log.error(\"No text provided for sentiment analysis\")\n",
    "                analysis_results.append(\"No text provided for sentiment analysis\")\n",
    "            elif \"Expecting value\" in str(e):\n",
    "                if \"Unterminated string\" in str(e):\n",
    "                    log.warning(\"JSON string is unterminated\")\n",
    "                    analysis_results.append(raw_json)\n",
    "                elif \"I'm sorry, but I need some text to perform the sentiment extraction\" in str(e):\n",
    "                    log.error(\"No text provided for sentiment analysis\")\n",
    "                    analysis_results.append(\"No text provided for sentiment analysis\")\n",
    "                else:\n",
    "                    log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "                    analysis_results.append([])\n",
    "            else:\n",
    "                log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "                analysis_results.append([])\n",
    "        except Exception as e:\n",
    "            log.error(f\"Error performing sentiment analysis on text: {text}\")\n",
    "            log.error(str(e))\n",
    "            analysis_results.append([])\n",
    "    else: #hier stond else\n",
    "        traceback.print_exc()\n",
    "        log.warning(f\"No id found in row {i}. Skipping analysis.\")\n",
    "        analysis_results.append([])\n",
    "        \n",
    "    #time.sleep(2) #added 2 seconds delay between requests\n",
    "\n",
    "df[\"analysis\"] = analysis_results\n",
    "df.to_csv(\"./feedbacks_analysis_2011-2014.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL VERSION\n",
    "import time \n",
    "import traceback\n",
    "from textwrap import dedent\n",
    "from random import choice\n",
    "from tqdm.notebook import tqdm\n",
    "#from absa.analysis.gpt3 import analyze\n",
    "from json import loads\n",
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "import time\n",
    "from json import JSONDecodeError, loads\n",
    "from tqdm import tqdm\n",
    "\n",
    "retry_attempts = 3\n",
    "retry_delay = 2\n",
    "analysis_results = []\n",
    "extra_prompts = []\n",
    "\n",
    "completion_text_conversation = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance by extracting \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Gmünder, Kegel, Kastberger, Keller, Feßmann, Steiner needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Dinić, Dorian, Gardi, Lehn, Macht, Özdogan, Otoo, Sargnagel, Schenk, Schneider, Snela, Sozio, Wolf, Zwicky. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a list of JSON objects. The confidence score is represented as a string in the output. The order of the list of JSON objects is the same as the order in which the opinions were expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2007 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance by extracting \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Sulzer, Feßmann, Spinnen, Jandl, Fleischanderl, Winkels, Keller, Mangold, Strigl, Heiz, März, Nüchtern, Ebel, Rakusa, Corino, Radisch needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Janesch, Altwasser, Kloeble, Mezger, Elmiger, Ballhausen, Scharnigg, Scholz, Zander, Kleindienst, Wawerzinek, Schmidt, Fries, Rossbacher, Langenegger, Weiss, Krampitz, Preisendörfer, Neudecker, Stift, Bönt, Ruch, Petersen, Schäfer, Sander, Winkler, Born, Satanik, Palzhoff, Bronsky, Setz, Reitzer, Arndt, Findeis, Orths, Geißler, Mohafez, Hintze, Lenz, Ziegler, Rammstedt, Selg, Marinič, Bernhardt, Schmidt, Grill, Albrecht, Schley, Seiler, Scheuermann, Reng, Zwicky, Stavarič, Oda, Oesterle, PeterLicht, Böttcher, Kern, Stangl, Becker. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a list of JSON objects. The confidence score is represented as a string in the output. The order of the list of JSON objects is the same as the order in which the opinions were expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target in each sentence separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2014 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance. The aspect categories and their aspect terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Dusini, Feßmann, Steiner, Winkels, Strigl, Spinnen, Sulzer, Jandl, Caduff, Keller needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Marchel, Preiwuß, Sommer, Klemm, Flor, Heier, Pölzl, Varatharajah, Fehr, Ganzoni, Gericke, Rubinowitz, Petz, Köhler, Boehning, Meyerhoff, Kegele, Güntner, Mueller, Rock, Simon, Helle, Schönthaler, Petrowskaja, Dübgen, Ehrlich, Maack, Mehlhorn, Moster, Ramnek, Richner, Stichmann, Hassinger, Mahlke, Travnicek, Martynova, Kränzler, Froehling, Nawrat, Senkel, Federmair, Feimer, Geltinger, Steinbeis, Wisser, Praßler, Baum, Reichlin, Haderlap, Rabinowich, Bußmann, Popp, Randt, Richter, Božiković, Klupp. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a JSON object or a list of JSON objects comprising \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" and their values as list of dictionaries as the top-level objects. Do not add \\\"results\\\", \\\"aspect_extraction\\\" or other descriptive terms as top-level JSON object. The confidence score is represented as a string in the output. The order is the same as the order expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "completion_text_conversation2015 = \"\"\"\n",
    "Please perform quadruple sentiment extraction on this utterance. The aspect categories and their aspect terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Strigl, Spinnen, Dusini, Feßmann, Steiner, Keller, Jandl needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Marchel, Preiwuß, Sommer, Klemm, Flor, Heier, Pölzl, Varatharajah, Fehr, Ganzoni, Gericke, Rubinowitz, Petz, Köhler, Boehning, Meyerhoff, Kegele, Güntner, Mueller, Rock, Simon, Helle, Schönthaler, Petrowskaja, Dübgen, Ehrlich, Maack, Mehlhorn. Any other name is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. The output is a single JSON object that contains a JSON object or a list of JSON objects comprising as key-value pairs \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" as list of dictionaries as the top-level objects. Do not add \\\"results\\\", \\\"aspect_extraction\\\" or other descriptive terms as top-level JSON object. The confidence score is represented as a string in the output. The order is the same as the order expressed in the text. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain. Analyze sentiment for each opinion target separately. All entities mentioned in the text do belong to at least one of the aspect categories and terms.\\n\\n\n",
    "\"\"\"\n",
    "logging.getLogger(\"openai\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing reviews\"):\n",
    "    try:\n",
    "        if pd.notnull(row[\"title\"]):\n",
    "            title = row[\"title\"]\n",
    "            text = row[\"text\"]\n",
    "            log.info(f\"Analyzing feedback - \\nID: {row['title']}\\nTitle: {title}\\nText: {text}\\n\")\n",
    "\n",
    "            res = create_completion(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=\"0.2\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\",    \"content\": \"You are a data analyst that provides multi-target quadruple sentiment extraction.\"},\n",
    "                    {\"role\": \"system\",    \"content\": \"You annotate multiple opinion targets per line if the text contains more than one target. You annotate every single target only once. If the input text does not seem to contain any opinion targets or expressions, assume as opinion target the first noun and as expression the rest of the utterance. Hashtags and weblinks are not targets. Do not invent aspect categories or aspect terms yourself.\"},\n",
    "                    {\"role\": \"user\",      \"content\": completion_text_conversation2015 + text + \":\"},    \n",
    "                    #{\"role\": \"user\",      \"content\": \"What is the most likely \"},\n",
    "                    #{\"role\": \"user\",      \"content\": \"Where are most of the students from?\"},\n",
    "                    #{\"role\": \"user\",      \"content\": \"Which extra-curricular activity/activities is most popular? Which among them has the highest female participation?\"},\n",
    "                    # add in as many questions as you want\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                raw_json = res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                #print(raw_json)\n",
    "                json_data = loads(raw_json)\n",
    "                analysis_results.append(json_data)\n",
    "\n",
    "                log.debug(f\"JSON response: {pprint(json_data)}\")\n",
    "\n",
    "                extra_prompts.append(f\"\\n{text}\\n{raw_json}\")\n",
    "\n",
    "            except JSONDecodeError as e:\n",
    "                if \"Unfortunately, it seems that there is no text provided in your request for me to perform sentiment extraction on.\" in str(e):\n",
    "                    log.error(\"No text provided for sentiment analysis\")\n",
    "                    analysis_results.append(\"No text provided for sentiment analysis\")\n",
    "                elif \"Expecting value\" in str(e):\n",
    "                    if \"Unterminated string\" in str(e):\n",
    "                        log.warning(\"JSON string is unterminated\")\n",
    "                        analysis_results.append(raw_json)\n",
    "                    elif \"I'm sorry, but I need some text to perform the sentiment extraction\" in str(e):\n",
    "                        log.error(\"No text provided for sentiment analysis\")\n",
    "                        analysis_results.append(\"No text provided for sentiment analysis\")\n",
    "                    else:\n",
    "                        log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "                        analysis_results.append([])\n",
    "                else:\n",
    "                    log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "                    analysis_results.append([])\n",
    "            except Exception as e:\n",
    "                log.error(f\"Error performing sentiment analysis on text: {text}\")\n",
    "                log.error(str(e))\n",
    "                analysis_results.append([])\n",
    "        else:\n",
    "            log.warning(f\"No id found in row {i}. Skipping analysis.\")\n",
    "            analysis_results.append([])\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        log.warning(f\"The error ecountered, {i}. Skipping analysis.\")\n",
    "        analysis_results.append([])\n",
    "        \n",
    "    #time.sleep(2) #added 2 seconds delay between requests\n",
    "\n",
    "df[\"analysis\"] = analysis_results\n",
    "df.to_csv(\"./feedbacks_analysis_2015_jury_batch1.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emergency procedure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disconnect emergency procedure\n",
    "#print(analysis_results)\n",
    "len(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_results) #shows the number of rows in the dataframe, insert this in the cell mentioning df.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(80)[\"analysis\"] = analysis_results\n",
    "df.to_csv(\"./feedbacks_analysis_2011-2014_0504_eerste80disconnect.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.head(80).index, \"analysis\"] = analysis_results #moans about deprecation, but the results are written\n",
    "df.to_csv(\"./feedbacks_analysis_2011-2014_0504_eerste80disconnect_tweedemanier.csv\", index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments to understand what the prompts do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(res_comp.json(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "#openai.api_key = \"キー\"\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    message=[        {            \"role\": \"user\",            \"content\": \"質問\"        }    ]\n",
    ")\n",
    "print(res[\"choices\"][0][\"text\"].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages = [{\"role\": \"system\", \"content\" : \"You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"},\n",
    "{\"role\": \"user\", \"content\" : \"How are you?\"},\n",
    "{\"role\": \"assistant\", \"content\" : \"I am doing well\"},\n",
    "{\"role\": \"user\", \"content\" : \"What is the mission of the company OpenAI?\"}]\n",
    ")\n",
    "#print(completion)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text = \"\"\"\n",
    "The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "res_comp = create_completion(completion_text, model=\"text-davinci-003\", max_tokens=500, temperature=0.2, top_p=1, n=1, stream=False, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text_conversation = \"\"\"\n",
    "Convert movie titles into emoji.\n",
    "\n",
    "Back to the Future: 👨👴🚗🕒 \n",
    "Batman: 🤵🦇 \n",
    "Transformers: 🚗🤖 \n",
    "Star Wars:\n",
    "\"\"\"\n",
    "res = create_completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    #message=[        {            \"role\": \"user\",            \"content\": \"質問\"        }    ]\n",
    "#)\n",
    "    #print(res[\"choices\"][0][\"text\"].strip())\n",
    "    messages=[\n",
    "            {\"role\": \"system\",    \"content\": \"You are a helpful bot\"},\n",
    "            #{\"role\": \"system\",    \"content\": prompt2},\n",
    "            {\"role\": \"user\",      \"content\": completion_text_conversation},\n",
    "            #{\"role\": \"user\",      \"content\": \"What is most popular major or group of majors?\"},\n",
    "            #{\"role\": \"user\",      \"content\": \"Where are most of the students from?\"},\n",
    "            #{\"role\": \"user\",      \"content\": \"Which extra-curricular activity/activities is most popular? Which among them has the highest female participation?\"},\n",
    "            # add in as many questions as you want\n",
    "        ],\n",
    ")\n",
    "print(res.json()[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing with individual examples without csv file\n",
    "completion_text_conversation = \"\"\"\n",
    "Please classify the German text in terms of \\\"Aspect Category\\\", \\\"Aspect Term\\\", \\\"Opinion Target\\\", \\\"Opinion Expression\\\", \\\"Sentiment\\\" and \\\"Confidence Score\\\" using the original language of the text. Do not invent \\\"Aspect Category\\\" or \\\"Aspect Term\\\" yourself. The aspect categories and their terms are: \\\"TEXT: Title\\\", \\\"TEXT:  Quote\\\", \\\"TEXT: PoV_Narration\\\", \\\"TEXT: Motifs_Themes\\\", \\\"TEXT: Language_Style_\\\", \\\"TEXT: General-Content_Plot\\\", \\\"TEXT: General\\\", \\\"TEXT: Form\\\", \\\"TEXT: Flow_Rhythm_Punctuation\\\", \\\"TEXT: Characters\\\", \\\"READING: Pronunciation_Intonation_Understandability\\\", \\\"READING: General\\\", \\\"READING: Flow_Rhythm_Punctuation\\\", \\\"ONSITE-AUDIENCE: General\\\", \\\"ONSITE-AUDIENCE: Behaviour\\\", \\\"ONSITE-AUDIENCE: Appearance_Clothing\\\", \\\"ONSITE-AUDIENCE: Age\\\", \\\"META: Winner_Award-Ceremony\\\", \\\"META: Weather\\\", \\\"META: Voting\\\", \\\"META: Videoportrait\\\", \\\"META: Technology_Social-Media\\\", \\\"META: Side-Event\\\", \\\"META: Shortlist\\\", \\\"META: Opening-Speech\\\", \\\"META: Online-Assessment\\\", \\\"META: Music\\\", \\\"META: Montage\\\", \\\"META: Main-Event\\\", \\\"META: Longlist\\\", \\\"META: Location\\\", \\\"META: Literature_Literary-Prizes\\\", \\\"JURY: Voice_Language-Use\\\", \\\"JURY: Quote\\\", \\\"JURY: General\\\", \\\"JURY: Discussion_Valuation\\\", \\\"JURY: Behaviour\\\", \\\"JURY: Appearance_Clothing\\\", \\\"CONTENDER: Quote\\\", \\\"CONTENDER: General\\\", \\\"CONTENDER: Gender\\\", \\\"CONTENDER: Appearance_Clothing\\\", \\\"ALLO-REFERENCES: TEXT_Other-Text\\\", \\\"ALLO-REFERENCES: TEXT_Other-Author\\\", \\\"ALLO-REFERENCES: SCREEN_Film_Tv\\\", \\\"ALLO-REFERENCES: SCREEN_Director_Actor\\\", \\\"ALLO-REFERENCES: MUSIC_Musician\\\", \\\"ALLO-REFERENCES: General\\\". Any reference to one of the names Winkels, Gmünder, Kegel, Kastberger, Keller, Feßmann, Steiner needs to be classified as \\\"JURY: Name\\\". Any reference to either one of the following names needs to be classified as \\\"CONTENDER: Name\\\": Dinić, Dorian, Gardi, Lehn, Macht, Özdogan, Otoo, Sargnagel, Schenk, Schneider, Snela, Sozio, Wolf, Zwicky. Any reference to any other named entity persons is to be seen as belonging to the Aspect Category \\\"ALLO-REFERENCE\\\". The Sentiment is  \\\"positive\\\", \\\"neutral\\\" or \\\"negative\\\". The numeric confidence score ranges between -1 and 1 and is rounded to hundreds and tens. Format output as JSON. Ignore the hashtags and the weblinks. Reply only with the json. Do not explain.\\n\\n Lohnarbeit ist Demütigung - immer und überall. Das Buch ist wirklich scheiße. #tddl16 #sargnagel:\n",
    "\"\"\"\n",
    "#der Akzent des Autors ist so sympathisch. Aber dieser Juror, der da redet. Dieser selbstgefällige kleine Meckerer. Der fängt an, zu nerven. Wray performt zu viel mit den Händen. Das lenkt zu sehr vom Text ab #tddl Sargnagel hat eine technisch, intellektuell und literarisch hervorragende Geschichte abgeliefert. Statt Thomas Bernhard werden Parallelen zu Wolf Haas gezogen. Auch das ist wohltuend an der Diskussion:\\n\\n    [\\n      {{ \\\"aspect category\\\": \\\"CONTENDER\\\", \\\"aspect term\\\": \\\"Appearance_Clothing\\\", \\\"opinion target\\\": \\\"Akzent des Autors\\\", \\\"opinion expression\\\": \\\"ist so sympathisch\\\", \\\"sentiment\\\": \\\"positive\\\", \\\"confidence score\\\": \\\"1\\\" }},\\n      {{ \\\"aspect category\\\": \\\"JURY\\\", \\\"aspect term\\\": \\\"Behaviour\\\", \\\"opinion target\\\": \\\"dieser Juror, der da redet\\\", \\\"opinion expression\\\": \\\"Dieser selbstgefällige kleine Meckerer\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"confidence score\\\": \\\"-1\\\" }},\\n      {{ \\\"aspect category\\\": \\\"JURY\\\", \\\"aspect term\\\": \\\"Behaviour\\\", \\\"opinion target\\\": \\\"dieser Juror, der da redet\\\", \\\"opinion expression\\\": \\\"fängt an, zu nerven\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"confidence score\\\": \\\"-1\\\" }},\\n      {{ \\\"aspect category\\\": \\\"CONTENDER\\\", \\\"aspect term\\\": \\\"Appearance_Clothing\\\", \\\"opinion target\\\": \\\"Sargnagel\\\", \\\"opinion expression\\\": \\\"performt zu viel mit den Händen\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"confidence score\\\": \\\"-0.7\\\" }},\\n      {{ \\\"aspect category\\\": \\\"TEXT\\\", \\\"aspect term\\\": \\\"Language_Style\\\", \\\"opinion target\\\": \\\"Geschichte\\\", \\\"opinion expression\\\": \\\"technisch, intellektuell und literarisch hervorragende\\\", \\\"sentiment\\\": \\\"positive\\\", \\\"confidence score\\\": \\\"0.7\\\" }},\\n      {{ \\\"aspect category\\\": \\\"ALLO-REFERENCE\\\", \\\"aspect term\\\": \\\"Other-Author\\\", \\\"opinion target\\\": \\\"werden Parallelen zu Wolf Haas gezogen\\\", \\\"opinion expression\\\": \\\"das ist wohltuend an der Diskussion\\\", \\\"sentiment\\\": \\\"positive\\\", \\\"confidence score\\\": \\\"0.5\\\" }}\\n       {{ \\\"aspect category\\\": \\\"ALLO-REFERENCE\\\", \\\"aspect term\\\": \\\"Other-Author\\\", \\\"opinion target\\\": \\\"Thomas Bernhard \\\", \\\"opinion expression\\\": \\\"statt\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"confidence score\\\": \\\"-0.1\\\" }}\\n    ]\\n\\n    Der Text handelt vom Überleben in den Konzentrationslagern und wird aus der Sicht eines unzuverlässigen Erzählers erzählt. Der Text von Peschka hingegen: Beklemmend. Dumpf. Spröde. Karg. Verstörend. Irritierend. - Ein Endspiel Eingeschlossener mit Mäusen in ihren Bunkern. - Es fröstelt mich, trotz der Hitze im Text. Eindringlich. Geduldiges Warten im Saal. Ich finde die Jury heuer so zahm und alles irgendwie gutfindend. Einige Besucher nutzen den Text als Fächer. Wahrscheinlich das Beste, was man damit machen kann.:\\n\\n    [\\n      {{ \\\"aspect category\\\": \\\"TEXT\\\", \\\"aspect term\\\": \\\"Motifs_Themes\\\", \\\"opinion target\\\": \\\"der Text\\\", \\\"opinion expression\\\": \\\"handelt vom Überleben in den Konzentrationslagern\\\", \\\"sentiment\\\": \\\"neutral\\\", \\\"confidence score\\\": \\\"1\\\" }},\\n      {{ \\\"aspect category\\\": \\\"TEXT\\\", \\\"aspect term\\\": \\\"PoV_Narration\\\", \\\"opinion target\\\": \\\"der Text\\\", \\\"opinion expression\\\": \\\"wird aus der Sicht eines unzuverlässigen Erzählers erzählt\\\", \\\"sentiment\\\": \\\"neutral\\\", \\\"confidence score\\\": \\\"0\\\" }},\\n      {{ \\\"aspect category\\\": \\\"TEXT\\\", \\\"aspect term\\\": \\\"Language_Style\\\", \\\"opinion target\\\": \\\"Der Text von Peschka\\\", \\\"opinion expression\\\": \\\"Beklemmend. Dumpf. Spröde. Karg. Verstörend. Irritierend. \\\", \\\"sentiment\\\": \\\"positiv\\\", \\\"confidence score\\\": \\\"0,3\\\" }},\\n      {{ \\\"aspect category\\\": \\\"TEXT\\\", \\\"aspect term\\\": \\\"Motifs_Themes\\\", \\\"opinion target\\\": \\\"Eingeschlossener mit Mäusen in ihren Bunkern\\\", \\\"opinion expression\\\": \\\"ein Endspiel\\\", \\\"sentiment\\\": \\\"neutral\\\", \\\"confidence score\\\": \\\"0\\\" }},\\n      {{ \\\"aspect category\\\": \\\"ONSITE-AUDIENCE\\\", \\\"aspect term\\\": \\\"Behaviour\\\", \\\"opinion target\\\": \\\"im Saal\\\", \\\"opinion expression\\\": \\\"Geduldiges Warten\\\", \\\"sentiment\\\": \\\"neutral\\\", \\\"confidence score\\\": \\\"0\\\" }}\\n       {{ \\\"aspect category\\\": \\\"JURY\\\", \\\"aspect term\\\": \\\"valuation\\\", \\\"opinion target\\\": \\\"die Jury\\\", \\\"opinion expression\\\": \\\"heuer so zahm und alles irgendwie gutfindend\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"confidence score\\\": \\\"-0,3\\\" }}\\n       {{ \\\"aspect category\\\": \\\"ONSITE-AUDIENCE\\\", \\\"aspect term\\\": \\\"Behaviour\\\", \\\"opinion target\\\": \\\" Einige Besucher \\\", \\\"opinion expression\\\": \\\"nutzen den Text als Fächer.\\\", \\\"sentiment\\\": \\\"neutral\\\", \\\"confidence score\\\": \\\"0\\\" }}\\n       {{ \\\"aspect category\\\": \\\"ONSITE-AUDIENCE\\\", \\\"aspect term\\\": \\\"Behaviour\\\", \\\"opinion target\\\": \\\"nutzen den Text als Fächer\\\", \\\"opinion expression\\\": \\\"das Beste, was man damit machen kann\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"confidence score\\\": \\\"-0,3\\\" }}\\n    ]\\n\\n \n",
    "res = create_completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    #message=[        {            \"role\": \"user\",            \"content\": \"質問\"        }    ]\n",
    "#)\n",
    "    #print(res[\"choices\"][0][\"text\"].strip())\n",
    "    messages=[\n",
    "            {\"role\": \"system\",    \"content\": \"You are a data analyst that analyzes complex datasets and provides multi-target quadruple sentiment extraction.\"},\n",
    "            {\"role\": \"system\",    \"content\": \"You annotate multiple opinion targets per line. Hashtags and weblinks are not targets.\"},\n",
    "            {\"role\": \"user\",      \"content\": completion_text_conversation},\n",
    "            #{\"role\": \"user\",      \"content\": \"What is most popular major or group of majors?\"},\n",
    "            #{\"role\": \"user\",      \"content\": \"Where are most of the students from?\"},\n",
    "            #{\"role\": \"user\",      \"content\": \"Which extra-curricular activity/activities is most popular? Which among them has the highest female participation?\"},\n",
    "            # add in as many questions as you want\n",
    "        ],\n",
    ")\n",
    "#print(res)\n",
    "print(res.json()[\"choices\"][0][\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another test\n",
    "completion_text_conversation = \"\"\"\n",
    "Convert movie titles into emoji.\n",
    "\n",
    "Back to the Future: 👨👴🚗🕒 \n",
    "Batman: 🤵🦇 \n",
    "Transformers: 🚗🤖 \n",
    "Star Wars:\n",
    "\"\"\"\n",
    "res = create_completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    #message=[        {            \"role\": \"user\",            \"content\": \"質問\"        }    ]\n",
    "#)\n",
    "    #print(res[\"choices\"][0][\"text\"].strip())\n",
    "    messages=[\n",
    "            {\"role\": \"system\",    \"content\": \"You are a helpful bot\"},\n",
    "            #{\"role\": \"system\",    \"content\": prompt2},\n",
    "            {\"role\": \"user\",      \"content\": completion_text_conversation},\n",
    "            #{\"role\": \"user\",      \"content\": \"What is most popular major or group of majors?\"},\n",
    "            #{\"role\": \"user\",      \"content\": \"Where are most of the students from?\"},\n",
    "            #{\"role\": \"user\",      \"content\": \"Which extra-curricular activity/activities is most popular? Which among them has the highest female participation?\"},\n",
    "            # add in as many questions as you want\n",
    "        ],\n",
    ")\n",
    "print(res.json()[\"choices\"][0][\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(res_comp)\n",
    "    #raw_json = res_comp[\"choices\"][0][\"text\"].strip() #res_comp ipv res\n",
    "    pprint(res_comp.json()['choices'][0]['text'], indent=2)\n",
    "    response_data = res_comp.json()\n",
    "    print(response_data)\n",
    "    raw_json = response_data[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(res.json(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "openai.api_key = \"key_here\"\n",
    "\n",
    "\n",
    "openai.aiosession.set(ClientSession())\n",
    "\n",
    "async def create_completion(prompt=\"How are you ?\"):\n",
    "    return await openai.ChatCompletion.acreate(messages=[{\"role\": \"user\", \"content\": prompt}], model=\"gpt-3.5-turbo\")\n",
    "\n",
    "async def main():\n",
    "\n",
    "    return await asyncio.gather(*[create_completion() for _ in range(14)])\n",
    "\n",
    "answers=await main()\n",
    "\n",
    "await openai.aiosession.get().close()\n",
    "\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text_conversation = \"\"\"\n",
    "Convert movie titles into emoji.\n",
    "\n",
    "Back to the Future: 👨👴🚗🕒 \n",
    "Batman: 🤵🦇 \n",
    "Transformers: 🚗🤖 \n",
    "Star Wars:\n",
    "\"\"\"\n",
    "res_comp = create_completion(completion_text_conversation, model=\"gpt-3.5-turbo\", max_tokens=500, temperature=0.2, top_p=1, n=1, stream=False, echo=False)\n",
    "pprint(res_comp.json()['choices'][0]['text'], indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text_summarization = \"\"\"\n",
    "Summarize this for a second-grade student:\n",
    "\n",
    "Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "res_comp = create_completion(completion_text_summarization, model=\"text-davinci-003\", max_tokens=500, temperature=0.2, top_p=1, n=1, stream=False, echo=False)\n",
    "pprint(res_comp.json()['choices'][0]['text'], indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text_episode = \"\"\"\n",
    "Write an episode for 2-minute speaking practice English under 100 words. This episode is for blog posts in markdown format. heading has 3 hashes. You are given main subject and subtopic as [main subject, subtopic]\n",
    "\n",
    "[Amusement Park, Parade is more fun than rides]: \n",
    "\"\"\"\n",
    "res_comp = create_completion(completion_text_episode, model=\"text-davinci-003\", max_tokens=500, temperature=0.2, top_p=1, n=1, stream=False, echo=False)\n",
    "pprint(res_comp.json(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text = \"\"\"\n",
    "I just created a new Github repository. How can I connect this repository to my local git?\n",
    "\n",
    "Description: \n",
    "\"\"\"\n",
    "res_comp = create_completion(completion_text, model=\"text-davinci-003\", max_tokens=500, temperature=0.2, top_p=1, n=1, stream=False, echo=False)\n",
    "print(\"\".join(res_comp.json()['choices'][0]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_text = \"\"\"\n",
    "I'd like to fix the following shell script. there are 5 zip files in the current directory. I want to unzip them into 5 different directories. The directory name should be added 7 to the original directory name. For example, '1월.zip' should be unzipped into '8월' directory.\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "for i in $(seq -w 1 5); do\n",
    "  unzip \"$i.*.zip\" -d \"$i\"\n",
    "done\n",
    "\n",
    "\n",
    "Description: \n",
    "\"\"\"\n",
    "res_comp = create_completion(completion_text, model=\"text-davinci-003\", max_tokens=500, temperature=0.2, top_p=1, n=1, stream=False, echo=False)\n",
    "print(\"\".join(res_comp.json()['choices'][0]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_code = \"\"\"\n",
    "How come I use my phone to check the weather? My teacher said that I should use.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_res = edit_prompt(\"Fix the sentence if the it looks awkward.\", input=example_code, model=\"text-davinci-edit-001\", num=1, temperature=0.2, top_p=1)\n",
    "print(edit_res.json())\n",
    "print(''.join(edit_res.json()['choices'][0]['text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "48ca3073c5549c1ccf4f4a58b2740315d5bce04ee37289cb933f5ff9b483ac6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
